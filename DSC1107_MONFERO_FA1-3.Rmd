---
title: "Data Wrangling"
author: "John Benedict A. Monfero"
date: "2025-01-31"
output: md_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### 1. Introduction
Unlike `diamonds`, data from the real world are not already built into an R package and are rarely are as clean.
 
This lecture is about **data wrangling**, the art of getting your data into R in a useful form for visualization and modeling. These notes draw on Chapters 10-15 from R4DS.

```{r library}
library(tidyverse)
```

### 2. Data Import (R4DS Chapter 11)
Data come in several different formats, e.g. comma-separated values (csv), tab-separated values (tsv), or Excel files. To read files in csv or tsv formats, use `read_csv` and `read_tsv`, respectively. These are both part of the `readr` package, which is part of the `tidyverse`. These functions are very similar to each other. To read Excel files, use the `read_excel` function from the `readxl` package.

```{r read_file}
heights = read_csv(file = "heights.csv")
heights
```

Note that `read_csv` has automatically inferred the types of each column. It also made the assumption that the first line of the file are the column names. Sometimes, this is not the case. If column names are absent, you should specify the `col_names` argument either as `FALSE` or as a character vector of column names. Sometimes the files you’d like to read contain headers, i.e. one or more lines of metadata before the actual
 data starts. In this case, you can either skip a fixed number of lines (e.g. the first three) via `skip = 3` or
 skip any lines starting with a certain character (e.g. #) via `comment = "#"`. It’s a good idea to first open the data file before deciding how to import it.
 
**Exercise: Import heights2.csv**
```{r exercise_import}
heights_dummy = read_csv(file = "heights2.csv")
heights_dummy
```
### 3. Tidy Data using Tibble

 In this section, you will learn a consistent way to organise your data in R, an organisation called tidy data.
 Getting your data into this format requires some upfront work, but that work pays off in the long term. Once
 you have tidy data and the tidy tools provided by packages in the tidyverse, you will spend much less time
 munging data from one representation to another, allowing you to spend more time on the analytic questions
 at hand.
 
 *There are multiple ways to represent the same data:*
```{r tidy_table1}
table1 <- tribble(
  ~country,     ~year, ~cases,       ~population,
  "Afghanistan", 1999, 745,         19987071,
  "Afghanistan", 2000, 2666,        20595360,
  "Brazil",      1999, 37737,       172006362,
  "Brazil",      2000, 80488,       174504898,
  "China",       1999, 212258,      1272915272,
  "China",       2000, 213766,      1280428583
)

# Show the data
print(table1)
```
```{r tidy_table2}
# Create table2 using tribble
table2 <- tribble(
  ~country,     ~year, ~type,       ~count,
  "Afghanistan", 1999, "cases",      745,
  "Afghanistan", 1999, "population", 19987071,
  "Afghanistan", 2000, "cases",      2666,
  "Afghanistan", 2000, "population", 20595360,
  "Brazil",      1999, "cases",      37737,
  "Brazil",      1999, "population", 172006362,
  "Brazil",      2000, "cases",      80488,
  "Brazil",      2000, "population", 174504898,
  "China",       1999, "cases",      212258,
  "China",       1999, "population", 1272915272,
  "China",       2000, "cases",      213766,
  "China",       2000, "population", 1280428583
)

# Show the data
print(table2)
```
```{r tidy_table3}
# Create table3
table3 <- tribble(
  ~country, ~year, ~rate,
  "Afghanistan", 1999, "745/19987071",
  "Afghanistan", 2000, "2666/20595360",
  "Brazil", 1999, "37737/172006362",
  "Brazil", 2000, "80488/174504898",
  "China", 1999, "212258/1272915272",
  "China", 2000, "213766/1280428583"
)

# Show the data
print(table3)
```
```{r tidy_table4a}
# Create table4a
table4a <- tribble(
  ~country,     ~`1999`, ~`2000`,
  "Afghanistan", 745,    2666,
  "Brazil",      37737,  80488,
  "China",       212258, 213766
)

# Show the data
print(table4a)
```

```{r tidy_table4b}
# Create table4b
table4b <- tribble(
  ~country,     ~`1999`,     ~`2000`,
  "Afghanistan", 19987071,   20595360,
  "Brazil",      172006362,  174504898,
  "China",       1272915272, 1280428583
)

# Show the data
print(table4b)
```

These are all representations of the same underlying data, but they are not equally easy to use. One dataset, the tidy dataset (`table1`), will be much easier to work with inside the `tidyverse`.

**“Happy families are all alike; every unhappy family is unhappy in its own way.”** *– Leo Tolstoy*

**“Tidy datasets are all alike, but every messy dataset is messy in its own way.”** *– Hadley Wickham*

All the packages in the `tidyverse` are designed to work with tidy data. The `tidyr` package is designed to
 get non-tidy data into tidy format
 
**Exercise: Using prose, describe how the variables and observations are organised in each of the sample tables.**

#####Answer: In this chapter, we are able to see that similar data where shown in distinct ways, they represent the data and its impacts to understand the dataset itself differently due to how observations and variables were distributed or organized. However, given datasets `table1`, `table2`, `table3`, `table4a` and `table4b`, `table1` would likely to be utilized and universally helpful than the other since it gives the most normalized-tidiest data to define how each country-year observes their cases and population respectively, as straigforward as is like considering the `country` and `year` would be the primary composite key of each data observations. The dilemma with `table2` would be it was overnormalized the dataset given the composite keys `country`, `year`, then the `type` of data will reveal, the issue is that it overutilizes much spaces - uneccesary rows - to render all data as compared to `table1`. Moreover, `table3` contains one variable `rate` but on each observation `rate` pertains to two relative values, it is not independent on its own column description rather it just showing two values that was compressed within one variable which is not ideal for data analysis. `table4a` and `table4b` would give the same dataset about `table1` but it delivers most incomprehensive relationship between `country`, and `1999` and `2000` to pertains or to denote regards with.

### 4. Pivoting
Once you get a non-tidy dataset, the first step is to figure out what the variables and observations are. Then,
 you want to get the variables into columns and get observations into rows.
 
 > If one variable is spread across multiple columns, you’ll need to pivot_longer.
 
 > If one observation is scattered across multiple rows, you’ll need to pivot_wider.
 
#### 4.1. Longer

 A common problem is a dataset where some of the column names are not names of variables, but values of a variable. Take `table4a`: the column names `1999` and `2000` represent values of the year variable, the values in the `1999` and `2000` columns represent values of the cases variable, and each row represents two observations, not one.
 
```{r pivoting_table4a}
table4a
```
 
To tidy a dataset like this, we need to **pivot** the offending columns into a new pair of variables. To describe that operation we need three parameters:

> `cols`: The set of columns whose names are values, not variables. In this example, those are the columns `1999` and `2000`.

> `names_to`: The name of the variable to move the column names to. Here it is `year`.

> `values_to`: The name of the variable to move the column values to. Here it’s `cases`.

```{r pivot_longer_table4a}
 table4a %>%
 pivot_longer(cols = c(`1999`, `2000`), names_to = "year", values_to = "cases")
```

**Exercise: Use `pivot_longer()` to tidy `table4b` in a similar fashion. What is the difference between the code used to tidy `table4a` and `table4b`?**
```{r exercise_pivot_longer}
 table4b %>%
  pivot_longer(cols= c(`1999`, `2000`), names_to = "year", values_to = "population")

  print("Both revised table4a and table4b is much like table1 however, the revised version was becomes clearer or tidier for each table - 4a and 4b but actually each table does not hold both variables that table1 describes each row")
```

 To combine the tidied versions of `table4a` and `table4b` into a single tibble, we need to use `left_join()` from the `dplyr` package. See Section 5 below.
 
#### 4.2. Wider
 `pivot_wider()` is the opposite of `pivot_longer()`. You use it when an observation is scattered across multiple rows. For example, take `table2`: an observation is a country in a year, but each observation is spread across two rows.

```{r pivoting_table2}
table2
```
 To tidy this up, we first analyse the representation in similar way to `pivot_longer()`. This time, however, we only need two parameters:

> The column to take variable names from. Here, it’s `type`.

> The column to take values from. Here it’s `count`.

Once we’ve figured that out, we can use `pivot_wider()`.

```{r pivot_wider_table2}
table2 %>%
 pivot_wider(names_from=type,values_from=count)
```
**Exercise: Why does this code below**

> "table4a %>%
pivot_longer(cols=c(1999,2000), names_to="year",values_to="cases")"

```{r}
 #Error: Can't subset columns that don't exist.
 print("The error exists is because the pivot_longer() for table4a tries to find the columns named `1999` and `2000` and not 1999 and 2000, thus these columns don't exist in the table table4a anymore; you need to ensure correct referencing of column names.")
 #Locations 1999 and 2000 don't exist.
 print("This reiterates the reason as the source of the error since pivot_longer() considers the parameter `cols` where each variable named as string instead of pure integer, on which column within `table4a` names shall be taken consider to transform.")
 #There are only 3 columns.
 print("Despite the presence of 3 columns, none of those columns contain the column names 1999 and 2000")
```

**Exercise: Tidy the simple tibble below. Do you need to make it wider or longer? What are the variables?**

```{r}
pregnant_population <- tribble(
 ~pregnant, ~male, ~female,
 "yes", NA, 10,
 "no", 20, 12
 )
print("Since the data does not offer any data whether there is a male pregnant, thus it is better to make the table pivot longer since we dont want to further describe what `yes` or `no` describes to two gender")

pregnant_population %>%
pivot_longer(cols = c(`male`, `female`), names_to = "gender", values_to = "count")

```
###5. Joining
 It’s rare that a data analysis involves only a single table of data. Typically you have many tables of data, and you must combine them to answer the questions that you’re interested in. Collectively, multiple tables of data are called relational data because it is the relations, not just the individual datasets, that are important. Recall the tidy versions of `table4a` and `table4b`:
 
```{r}
 tidy4a <- table4a %>%
 pivot_longer(c(`1999`, `2000`), names_to = "year", values_to = "cases")
```
 
```{r}
 tidy4b <- table4b %>%
 pivot_longer(c(`1999`, `2000`), names_to = "year", values_to = "population")
```

```{r}
 tidy4a
 tidy4b
```

 Joining two tables requires one or more **key** columns that are shared between the two tables. In this case, the key columns are `country` and `year`. There are several kinds of joins (see R4DS Chapter 13), but the
 most common is the `left join` (`left_join()` in `dplyr`). Given two tables *x* and *y*, `left_join(x,y)` tries to
 join *y* into *x*, keeping all rows in *x* (even if for some rows in *x* the key does not match any rows in *y*)
 
```{r}
 left_join(x = tidy4a, y = tidy4b, by = c("country", "year"))
```
 
 **Exercise: Consider the two tibbles below. What is the key column? Without writing any code, can you predict how many rows and columns `left_join(x,y)` and `left_join(y,x)` will have?**
 
```{r}
 x <- tribble(
 ~state, ~population,
 "PA", 12.8,
 "TX", 28.6,
 "NY", 19.5
 )
 y <- tribble(
 ~state, ~capital,
 "TX", "Austin",
 "CA", "Sacramento",
 "NY", "New York City",
 "MI", "Lansing"
 )
```
 
```{r}
left_join(x = x, y = y, by = c("state"))
print("There are 3 rows - 1 row with no data observation, and 3 columns given the left_join(x,y)")
```
 
```{r}
left_join(x = y, y = x, by = c("state"))
print("There are 4 rows - 2 row with no data observation, and 3 columns given the left_join(y,x)")
```
 
### 6. Seperating
 So far you’ve learned how to tidy `table2` and `table4`, but not `table3`. `table3` has a different problem: we have one column (`rate`) that contains two variables (cases and population). To fix this problem, we’ll need the `separate()` function.
 
`separate()` pulls apart one column into multiple columns, by splitting wherever a separator character appears. Take `table3`:

```{r}
table3
```
The rate column contains both `cases` and `population` variables, and we need to split it into two variables. `separate()` takes the name of the column to separate, and the names of the columns to separate into, as shown below.

```{r}
 table3 %>%
 separate(rate, into = c("cases", "population"))
```
By default, `separate()` will split values wherever it sees a non-alphanumeric character (i.e. a character that isn’t a number or letter). For example, in the code above, `separate()` split the values of rate at the forward slash characters. If you wish to use a specific character to separate a column, you can pass the character to the `sep` argument of `separate()`. For example, we could rewrite the code above as:

```{r}
table3 %>%
 separate(rate, into = c("cases", "population"), sep = "/")
```

Look carefully at the column types: you’ll notice that cases and population are character columns. This is the default behaviour in `separate()`: it leaves the type of the column as is. Here, however, it’s not very useful as those really are numbers. We can ask `separate()` to try and convert to better types using `convert=TRUE`:

```{r}
table3%>%
 separate(rate,into=c("cases", "population"),convert=TRUE)
```

You can also pass a vector of integers to `sep. separate()` will interpret the integers as positions to split at. Positive values start at 1 on the far - left of the strings; negative value start at - 1 on the far - right of the strings. When using integers to separate strings, the length of `sep` should be one less than the number of names in into.
```{r}
 table3%>%
 separate(year,into=c("century", "year"),sep=2)
```

###7. Missing Values
Missing values, marked with *NA*, are often present in real datasets. Consider the following simple dataset:

```{r}
 stocks<-tibble(
 year =c(2015,2015,2015,2015, 2016,2016,2016),
 qtr =c( 1, 2, 3, 4, 2, 3, 4),
 return=c(1.88,0.59,0.35, NA,0.92,0.17,2.66)
 )
 stocks
```

The *NA* means that the return for the fourth quarter of 2015 is missing. Changing the representation of a dataset can create more missing values. For example, let’s pivot wider:
```{r}
 stocks %>%
 pivot_wider(names_from = year, values_from = return)
```

We see now that the return for the first quarter of 2016, which does not appear in the original dataset (implicitly missing), becomes also an *NA* (explicitly missing). 

Usually it’s a good idea to treat missing values with care, e.g. by thinking about why those values might be missing in the first place. 

The simplest approach to dealing with missing values in a dataset is to remove all rows containing any missing values. This can be done via `na.omit()`. For example:

```{r}
stocks %>%
 na.omit()
```

